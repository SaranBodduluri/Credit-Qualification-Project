{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Credit_Qualification_Project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDyU60_GkRhN"
      },
      "source": [
        "##Credit Qualification Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKWd1YIykd_U"
      },
      "source": [
        "We will now build a machine learning model that will predict whether or not a loan will be approved for an applicant.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6nbIivskO6T"
      },
      "source": [
        "###Libraries "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qu-r672KZLna"
      },
      "source": [
        "import numpy as np #Numpy library is used for working with multi-dimensional arrays and matrices\n",
        "import matplotlib.pyplot as plt   #Matploblib library is used for plotting graphs\n",
        "import pandas as pd  #Pandas library is used for it's functionality with data-structures and their operations\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgABjga3kuGm"
      },
      "source": [
        "### Dataset\n",
        "\n",
        "This dataset is about past loans given by a bank to customer. The __Loan_train.csv__ data set includes details of 346 customers whose loan are already paid off or defaulted.\n",
        "\n",
        " \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmrzWEbFk0Dg"
      },
      "source": [
        "Importing the dataset using pandas library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qskyRF74nfMb"
      },
      "source": [
        "!wget -O loan_train.csv https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/loan_train.csv\n",
        "!wget -O loan_test.csv https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/loan_test.csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pWpf9huZLnd"
      },
      "source": [
        "df = pd.read_csv('loan_train.csv')\n",
        "df.head()\n",
        "#Let's see what the data has!\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uj5poVXm7u5H"
      },
      "source": [
        "> Remember that you can use a question mark after any method or function in the Jupyter notebook. To read more about how to use the `read_csv` function, use the code below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "V5jv_2mm7u5I"
      },
      "outputs": [],
      "source": [
        "pd.read_csv?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s78TIoOVhMHz"
      },
      "source": [
        "df['difference'] = pd.to_datetime(df['due_date']) - pd.to_datetime(df['effective_date'])\n",
        "df.drop(columns = ['effective_date','due_date'], inplace = True)\n",
        "#df['difference'] is the difference between the effective and due date\n",
        "\n",
        "#removing redundant columns\n",
        "df.drop(columns = ['Unnamed: 0.1'], inplace = True)  #Column unnamed 0 is equal to unnamed 0.1"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwl52dOLtG0f"
      },
      "source": [
        "#converting data into values\n",
        "\n",
        "df['loan_status'].replace(to_replace=['PAIDOFF','COLLECTION'], value=[1,0],inplace=True)\n",
        "df['education'].replace(to_replace=['High School or Below','Bechalor','college','Master or Above'], value=[0,1,2,3],inplace=True)\n",
        "df['difference'] = df['difference'].astype('int')\n",
        "\n",
        "X = df[['Unnamed: 0','Principal', 'terms', 'age', 'education', 'difference']]\n",
        "y = df['loan_status']\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we have different features, each has different scaling or range, we need to do scaling for better accuracy during training and for new dataset"
      ],
      "metadata": {
        "id": "Zu3L7jiKuoM6"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixnmaCzYZLnh"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
        "X[:5]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qu25y7-xZLnh"
      },
      "source": [
        "#Splitting the dataset into training and testing data\n",
        "#Ref: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=4)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6Gk6k5tZLni"
      },
      "source": [
        "#Importing Logistic Regression Model from sklearn library\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "#Making an object of the model class\n",
        "LR_Model = LogisticRegression()\n",
        "\n",
        "#Fitting the data into the model\n",
        "\n",
        "LR_Model = LR_Model.fit(X_train,y_train)\n",
        "\n",
        "#Using the model to predict some values\n",
        "\n",
        "y_predicted  = LR_Model.predict(X_test)\n",
        "y_predicted_probability  = LR_Model.predict_proba(X_test)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFBpLqBlt1Wj"
      },
      "source": [
        "print(y_test.to_numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjxpey58HnPz"
      },
      "source": [
        "#Probability \n",
        "print(y_predicted_probability)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBtG3gX0t3Ps"
      },
      "source": [
        "print(y_predicted)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQNVjyxajKYH"
      },
      "source": [
        "#checking the accuracy of our model\n",
        "from sklearn import metrics\n",
        "\n",
        "accuracy = metrics.accuracy_score( y_predicted,y_test )\n",
        " \n",
        "print(\"Accuracy : %s\" % \"{0:.3%}\".format(accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVD1DsfgZLnj"
      },
      "source": [
        "#Now, let's test on the some real testing data\n",
        "#We will do the same steps at we did while importing the training data\n",
        "\n",
        "#Reading the csv file\n",
        "testdf = pd.read_csv('loan_test.csv')\n",
        "\n",
        "#Introducing the difference column to the dataframe\n",
        "testdf['difference'] = pd.to_datetime(testdf['due_date']) - pd.to_datetime(testdf['effective_date'])\n",
        "testdf['difference'] = testdf['difference'].astype(int)\n",
        "\n",
        "#Dropping unused data\n",
        "testdf.drop(columns = ['Gender','effective_date','due_date','Unnamed: 0.1'], inplace = True)\n",
        "\n",
        "#Replacing column containing string value with numerical value\n",
        "testdf['loan_status'].replace(to_replace=['PAIDOFF','COLLECTION'], value=[1,0],inplace=True)\n",
        "testdf['education'].replace(to_replace=['High School or Below','Bechalor','college','Master or Above'], value=[0,1,2,3],inplace=True)\n",
        "\n",
        "#Droping extra unused column, and splitting the data into X and Y\n",
        "Xtest = testdf[['Unnamed: 0','Principal', 'terms', 'age', 'education', 'difference']]\n",
        "ytest = testdf['loan_status']\n",
        "\n",
        "#Standarising the data\n",
        "Xtest = preprocessing.StandardScaler().fit(Xtest).transform(Xtest)\n",
        "\n",
        "#Predicting Y using X\n",
        "y_testdf_predict = LR_Model.predict(Xtest)\n",
        "\n",
        "\n",
        "#Importing library to calculate the error\n",
        "from sklearn import metrics\n",
        "  \n",
        " #Print accuracy\n",
        "accuracy = metrics.accuracy_score( y_testdf_predict,ytest )\n",
        " \n",
        "print(\"Accuracy : %s\" % \"{0:.3%}\".format(accuracy))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "c_yEIf1A9pvV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}